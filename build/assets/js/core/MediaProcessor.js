import{MediaBunny}from"./MediaBunny.js";export class MediaProcessor{static async process({source:e,format:o,quality:t,trim:a,resize:n,onProgress:r}){const i=new MediaBunny.BlobSource(e),s=new MediaBunny.Input({source:i,formats:MediaBunny.ALL_FORMATS});let d;switch(o){case"mp4":d=new MediaBunny.Mp4OutputFormat;break;case"webm":d=new MediaBunny.WebMOutputFormat;break;case"mov":d=new MediaBunny.QuickTimeOutputFormat;break;default:throw new Error(`Unsupported format: ${o}`)}const c=new MediaBunny.Output({format:d,target:new MediaBunny.BufferTarget});let u={};if(t<100){let e;e=t>=80?25e5:t>=60?15e5:8e5,u={bitrate:e,forceTranscode:!0}}n&&n.width&&n.height&&(u.width=n.width,u.height=n.height,u.fit="fill",u.forceTranscode=!0);const l=await MediaBunny.Conversion.init({input:s,output:c,video:u,trim:a});return r&&(l.onProgress=r),await l.execute(),new Blob([c.target.buffer],{type:`video/${o}`})}static async getTracks(e){const o=new MediaBunny.BlobSource(e),t=new MediaBunny.Input({source:o,formats:MediaBunny.ALL_FORMATS}),a=await t.getVideoTracks(),n=await t.getAudioTracks(),r=async e=>Promise.all(e.map(async e=>{const o=await e.computeDuration(),t=await e.getCodecParameterString();return{id:e.id,type:e.type,language:e.languageCode,codec:e.codec,codecString:t,duration:o,width:e.displayWidth,height:e.displayHeight,channels:e.numberOfChannels,sampleRate:e.sampleRate}}));return{video:await r(a),audio:await r(n)}}static async extractTrack({source:e,trackIndex:o,trackType:t,format:a,onProgress:n}){const r=e instanceof Blob?new MediaBunny.BlobSource(e):new MediaBunny.BufferSource(e),i=new MediaBunny.Input({source:r,formats:MediaBunny.ALL_FORMATS});let s;switch(a){case"mp4":case"m4a":s=new MediaBunny.Mp4OutputFormat;break;case"mp3":s=new MediaBunny.Mp3OutputFormat;break;case"aac":s=new MediaBunny.AdtsOutputFormat;break;case"wav":s=new MediaBunny.WavOutputFormat;break;default:throw new Error(`Unsupported format: ${a}`)}const d=new MediaBunny.Output({format:s,target:new MediaBunny.BufferTarget}),c={input:i,output:d,video:(e,a)=>{const n="video"===t&&a-1===o;return console.log(`[MediaProcessor] Video track ${a} (${e.codec}): ${n?"KEEP":"DISCARD"} (Target: ${t} #${o})`),n?{}:{discard:!0}},audio:(e,a)=>{const n="audio"===t&&a-1===o;return console.log(`[MediaProcessor] Audio track ${a} (${e.codec}): ${n?"KEEP":"DISCARD"} (Target: ${t} #${o})`),n?{}:{discard:!0}}},u=await MediaBunny.Conversion.init(c);if(!u.isValid){console.error("Conversion invalid:",u.discardedTracks);const e=u.discardedTracks.map(e=>`${e.track.type}: ${e.reason}`).join(", ");throw new Error(`Cannot execute conversion: ${e}`)}n&&(u.onProgress=n),await u.execute();const l="video"===t?`video/${a}`:`audio/${a}`;return new Blob([d.target.buffer],{type:l})}static async merge({inputs:e,format:o="mp4",resolution:t,onProgress:a}){if(!e||e.length<2)throw new Error("At least 2 videos are required for merging.");console.log("[MediaProcessor] Starting merge of",e.length,"videos");const n=e;console.log("[MediaProcessor] Gathering metadata...");const r=[];for(const e of n){const o=new MediaBunny.Input({source:new MediaBunny.BlobSource(e),formats:MediaBunny.ALL_FORMATS}),t=await o.getPrimaryVideoTrack();if(!t)throw new Error("No video track found in input file");const a=null,n=null,i=await t.getDecoderConfig(),s=await t.computeDuration();r.push({duration:s,videoTrack:t,audioTrack:a,videoConfig:i,audioConfig:n})}const i=r[0],s=t?.width||i.videoConfig.codedWidth,d=t?.height||i.videoConfig.codedHeight,c=new MediaBunny.Output({target:new MediaBunny.BufferTarget,format:new MediaBunny.Mp4OutputFormat}),u=document.createElement("canvas");u.width=s,u.height=d;const l=u.getContext("2d"),g=new MediaBunny.CanvasSource(u,{codec:"avc",bitrate:1e7});c.addVideoTrack(g,{frameRate:30}),await c.start(),console.log("[MediaProcessor] Processing video frames...");let p=0,f=0,m=0;for(const e of r){const o=[];let t=null;console.log("[MediaProcessor] Decoder config:",JSON.stringify(e.videoConfig,null,2));const n=await VideoDecoder.isConfigSupported(e.videoConfig);if(console.log("[MediaProcessor] Codec support:",n),!n.supported)throw new Error(`Video codec not supported: ${e.videoConfig.codec}`);const i=new VideoDecoder({output:e=>o.push(e),error:e=>{console.error("[MediaProcessor] Video decoder error:",e),t=e}});try{i.configure(e.videoConfig);const o=new MediaBunny.EncodedPacketSink(e.videoTrack);let a=0;for await(const e of o.packets()){if(a<3&&console.log(`[MediaProcessor] Packet ${a}:`,{isKeyframe:e.isKeyframe,timestamp:e.timestamp,dataSize:e.data?.byteLength||0}),t)throw new Error(`Decoding failed at packet ${a}: ${t.message}`);if(e.data?.byteLength<50){a++;continue}const o=0===a;i.decode(new EncodedVideoChunk({type:o?"key":"delta",timestamp:1e6*e.timestamp,duration:e.duration?1e6*e.duration:void 0,data:e.data})),a++}if(console.log("[MediaProcessor] Processed",a,"packets, flushing..."),await i.flush(),t)throw new Error(`Decoding failed during flush: ${t.message}`)}finally{"closed"!==i.state&&i.close()}if(o.sort((e,o)=>e.timestamp-o.timestamp),o.length>0){const e=o[0].timestamp;for(let t=0;t<o.length;t++){const a=o[t],n=p+(a.timestamp-e)/1e6;let r;r=a.duration?a.duration/1e6:t<o.length-1?(o[t+1].timestamp-a.timestamp)/1e6:1/30,l.drawImage(a,0,0,s,d),await g.add(n,r),f=Math.max(f,n+r),a.close()}}p=f+1/30,m++,a&&a(m/(2*r.length))}return console.log("[MediaProcessor] Audio processing skipped (video-only merge)"),console.log("[MediaProcessor] Finalizing merge..."),g.close(),await c.finalize(),a&&a(1),console.log("[MediaProcessor] Merge complete!"),new Blob([c.target.buffer],{type:`video/${o}`})}}